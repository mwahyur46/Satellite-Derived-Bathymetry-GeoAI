{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73c6a185",
   "metadata": {},
   "source": [
    "# Satellite-Derived Bathymetry (SDB): Data Preprocessing\n",
    "\n",
    "This outlines explain data preprocessing workflow for Satellite-Derived Bathymetry (SDB) using Sentinel-2. The workflow transforms raw multispectral and field survey data into a clean dataset suitable for Geospatial Artificial Intelligence (GEOAI), using Machine Learning regression models.\n",
    "\n",
    "**Workflow Steps:**\n",
    "1.  **Sunglint Correction (Deglinting):** Application of the *Hedley et al. (2005) (https://doi.org/10.1080/01431160500034086)* method to remove sea-surface glint using the Near-Infrared (NIR) band. This improves the retrieval of subsurface reflectance in optically shallow waters.\n",
    "2.  **Land & Cloud Masking:** Calculation of the **Modified Normalized Difference Water Index (MNDWI)** to isolate water pixels and mask out land, clouds, and other non-water artifacts.\n",
    "3.  **Spatial Extraction:** Extraction of spectral reflectance values at exact coordinates corresponding to field survey sounding points (echosounder data).\n",
    "4.  **Dataset Splitting:** Partitioning data into Training (70%) and Testing (30%) sets for model development.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1b2f41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import rasterio\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import rasterio as rio\n",
    "from tqdm import tqdm\n",
    "\n",
    "from preprocessing.preprocessing import sunglint_correction, calculate_mndwi, extract_raster_value\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1909d5d",
   "metadata": {},
   "source": [
    "## 1. Atmospheric & Glint Correction\n",
    "The following block iterates through raw Sentinel-2 imagery to perform two critical corrections:\n",
    "\n",
    "1.  **Hedley Deglinting**: Uses the linear relationship between NIR (Band 8) and Visible bands (RGB) to subtract glint.\n",
    "    * *Equation*: $R'_i = R_i - b_i (R_{NIR} - Min_{NIR})$\n",
    "2.  **MNDWI Masking**: Uses Green and SWIR bands to detect water.\n",
    "    * *Threshold*: Pixels with MNDWI > 0.0 are classified as water."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1138e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8 images for processing.\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 1. CONFIGURATION & BATCH PROCESSING\n",
    "# ==========================================\n",
    "\n",
    "# --- Configuration (Constants) ---\n",
    "INPUT_DIR = r'data'\n",
    "OUTPUT_DIR = r'data\\corrected'\n",
    "PLOT_DIR = r'data\\corrected\\plot'  # For regression QA/QC plots\n",
    "\n",
    "# Processing Parameters\n",
    "MNDWI_THRESHOLD = 0.0  # Threshold > 0.0 typically indicates water\n",
    "\n",
    "# Create directories if they don't exist\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "os.makedirs(PLOT_DIR, exist_ok=True)\n",
    "\n",
    "# Find all TIF images\n",
    "tif_files = glob.glob(os.path.join(INPUT_DIR, \"*.tif\"))\n",
    "print(f\"Found {len(tif_files)} images for processing.\")\n",
    "\n",
    "# Sentinel-2 Band Mapping (Metadata)\n",
    "S2_BANDS = ['B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B8A', 'B9', 'B11', 'B12']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbad77ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:   0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images: 100%|██████████| 8/8 [00:10<00:00,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing complete. Quality control plots saved in 'plot' directory.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Main Processing Loop ---\n",
    "for filepath in tqdm(tif_files, desc=\"Processing Images\"):\n",
    "    filename = os.path.basename(filepath)\n",
    "    output_filepath = os.path.join(OUTPUT_DIR, f\"corrected_{filename}\")\n",
    "\n",
    "    try:\n",
    "        with rio.open(filepath) as src:\n",
    "            # 1. Read Data\n",
    "            data = src.read().astype('float32')\n",
    "            profile = src.profile.copy()\n",
    "            \n",
    "            # Validation: Ensure sufficient bands\n",
    "            if src.count < 12:\n",
    "                print(f\"[SKIP] {filename}: Insufficient bands ({src.count}/12).\")\n",
    "                continue\n",
    "\n",
    "            # 2. Define Band Indices (0-based)\n",
    "            # B2(Blue)=1, B3(Green)=2, B4(Red)=3, B8(NIR)=7, B11(SWIR)=10\n",
    "            idx_blue, idx_green, idx_red = 1, 2, 3\n",
    "            idx_nir = 7   \n",
    "            idx_swir = 10 \n",
    "\n",
    "            # Extract Bands\n",
    "            raw_bands = {\n",
    "                'blue': data[idx_blue],\n",
    "                'green': data[idx_green],\n",
    "                'red': data[idx_red],\n",
    "                'nir': data[idx_nir],\n",
    "                'swir': data[idx_swir]\n",
    "            }\n",
    "\n",
    "            # 3. Apply Hedley Sunglint Correction (Visible Bands)\n",
    "            # Returns clean RGB bands and saves regression plots for QC\n",
    "            corrected_rgb = sunglint_correction(\n",
    "                visible_bands=[raw_bands['blue'], raw_bands['green'], raw_bands['red']],\n",
    "                nir_band=raw_bands['nir'],\n",
    "                output_dir=PLOT_DIR,\n",
    "                image_id=filename,\n",
    "                plot_graphs=True\n",
    "            )\n",
    "            \n",
    "            clean_blue, clean_green, clean_red = corrected_rgb\n",
    "\n",
    "            # 4. Apply MNDWI Water Masking\n",
    "            # Formula: (Green - SWIR) / (Green + SWIR)\n",
    "            mndwi = calculate_mndwi(clean_green, raw_bands['swir'])\n",
    "            water_mask = mndwi > MNDWI_THRESHOLD\n",
    "\n",
    "            # 5. Reconstruct & Mask Final Image\n",
    "            final_stack = data.copy()\n",
    "            \n",
    "            # Update RGB with deglinted values\n",
    "            final_stack[idx_blue] = clean_blue\n",
    "            final_stack[idx_green] = clean_green\n",
    "            final_stack[idx_red] = clean_red\n",
    "            \n",
    "            # Apply Water Mask to ALL bands (Land = 0)\n",
    "            for b in range(src.count):\n",
    "                final_stack[b] = np.where(water_mask, final_stack[b], 0)\n",
    "\n",
    "            # 6. Save Corrected Image\n",
    "            profile.update(dtype='float32', nodata=0)\n",
    "            \n",
    "            with rio.open(output_filepath, 'w', **profile) as dst:\n",
    "                dst.descriptions = tuple(S2_BANDS)\n",
    "                dst.write(final_stack)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] {filename}: {e}\")\n",
    "\n",
    "print(\"\\nProcessing complete. Quality control plots saved in 'plot' directory.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3171e3b",
   "metadata": {},
   "source": [
    "## 2. Training Dataset Creation\n",
    "We now match the **corrected satellite imagery** with the **field survey depth data**.\n",
    "* **Input**: Corrected Sentinel-2 Image (.tif) & Sounding Points (.shp)\n",
    "* **Process**: Extract spectral values (features) at each sounding location.\n",
    "* **Output**: Cleaned NumPy arrays (.npy) ready for Machine Learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104de9b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading sounding data...\n",
      "Geometry Type: ['Point']\n",
      "Total Sounding Points: 1055\n",
      "    z1                           geometry\n",
      "0 -1.4  POINT Z (113.24407 -7.67952 -1.4)\n",
      "1 -1.4  POINT Z (113.24416 -7.67946 -1.4)\n",
      "2 -1.6  POINT Z (113.24416 -7.67946 -1.6)\n",
      "3 -1.6  POINT Z (113.24422 -7.67935 -1.6)\n",
      "4 -1.4  POINT Z (113.24424 -7.67926 -1.4)\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 2. LOAD SURVEY DATA\n",
    "# ==========================================\n",
    "\n",
    "# Configuration (Constants)\n",
    "SOUNDING_PATH = r'data\\sounding\\sounding.shp'\n",
    "# Select the specific image to match with survey data\n",
    "RASTER_PATH = r'data\\corrected\\corrected_s2_giliketapang_2018-05-31.tif'\n",
    "OUTPUT_DATASET_PATH = r'train-test dataset'\n",
    "DEPTH_COL = 'z1'  # Target variable column name\n",
    "\n",
    "# Setup\n",
    "os.makedirs(OUTPUT_DATASET_PATH, exist_ok=True)\n",
    "\n",
    "# Load Shapefile\n",
    "print(\"Loading sounding data...\")\n",
    "gdf_points = gpd.read_file(SOUNDING_PATH)\n",
    "\n",
    "print(f\"Geometry Type: {gdf_points.geom_type.unique()}\")\n",
    "print(f\"Total Sounding Points: {len(gdf_points)}\")\n",
    "print(gdf_points[[DEPTH_COL, 'geometry']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d799ba66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features from: corrected_s2_giliketapang_2018-05-31.tif\n",
      "Processing: corrected_s2_giliketapang_2018-05-31.tif\n",
      "  - Reprojecting points from EPSG:4326 to EPSG:32749...\n",
      "  - Extracting pixel values for 1055 points...\n",
      "Cleaning dataset (removing NaNs and Masked values)...\n",
      "Original Samples: 1055\n",
      "Valid Samples:    1054 (Dropped 1)\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 3. PIXEL EXTRACTION & CLEANING\n",
    "# ==========================================\n",
    "\n",
    "print(f\"Extracting features from: {os.path.basename(RASTER_PATH)}\")\n",
    "\n",
    "# 1. Extract Values\n",
    "# (Assumes extract_raster_value handles reprojection internally)\n",
    "X_features, y_labels = extract_raster_value(gdf_points, RASTER_PATH, DEPTH_COL)\n",
    "\n",
    "# 2. Data Cleaning\n",
    "print(\"Cleaning dataset (removing NaNs and Masked values)...\")\n",
    "\n",
    "# A. Remove NaNs (Invalid pixels/Outside raster extent)\n",
    "mask_no_nan = ~np.isnan(X_features).any(axis=1) & ~np.isnan(y_labels)\n",
    "\n",
    "# B. Remove Zeros (Masked Land/Clouds)\n",
    "# If a pixel is 0.0 in all bands, it was masked in Step 1.\n",
    "mask_water_only = np.all(X_features != 0, axis=1)\n",
    "\n",
    "# Combined Mask\n",
    "valid_mask = mask_no_nan & mask_water_only\n",
    "\n",
    "X_clean = X_features[valid_mask]\n",
    "y_clean = y_labels[valid_mask]\n",
    "\n",
    "print(f\"Original Samples: {len(X_features)}\")\n",
    "print(f\"Valid Samples:    {len(X_clean)} (Dropped {len(X_features) - len(X_clean)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6c4bc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partitioning dataset...\n",
      "Saving artifacts...\n",
      "------------------------------\n",
      "Success! Dataset saved to: 'train-test dataset'\n",
      "Train Shape: X=(737, 12), y=(737,)\n",
      "Test Shape:  X=(317, 12),  y=(317,)\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 4. SPLIT & SAVE\n",
    "# ==========================================\n",
    "\n",
    "# 1. Train/Test Split (70/30)\n",
    "print(\"Partitioning dataset...\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_clean, y_clean, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# 2. Save to Disk\n",
    "print(\"Saving artifacts...\")\n",
    "np.save(os.path.join(OUTPUT_DATASET_PATH, 'X_train.npy'), X_train)\n",
    "np.save(os.path.join(OUTPUT_DATASET_PATH, 'X_test.npy'), X_test)\n",
    "np.save(os.path.join(OUTPUT_DATASET_PATH, 'y_train.npy'), y_train)\n",
    "np.save(os.path.join(OUTPUT_DATASET_PATH, 'y_test.npy'), y_test)\n",
    "\n",
    "print(\"-\" * 30)\n",
    "print(f\"Success! Dataset saved to: '{OUTPUT_DATASET_PATH}'\")\n",
    "print(f\"Train Shape: X={X_train.shape}, y={y_train.shape}\")\n",
    "print(f\"Test Shape:  X={X_test.shape},  y={y_test.shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geoai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
